{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Science Nanodegree - Blog Post\n",
    "Created By: Renan Vieira Dias  \n",
    "https://review.udacity.com/#!/rubrics/1507/view\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Article Title: What data tells about dataÂ jobs\n",
    "\n",
    "- KeyWords: Data, Job, Work, Employ, Skills, Language, Salary, Experience, Seniority, Languages, Database, Technologies \n",
    " - Brain Storm:\n",
    "    - Requirements for Data Jobs\n",
    "    - Data Jobs tools\n",
    "    - What Data tells about Data Jobs\n",
    "    - How much each skill is worth it on data\n",
    "    - Technologies for Data Analyst, Data Science, Data Engineer, Database Administrator\n",
    "    - Technologies for Data Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "  \n",
    "- **Which skills and technologies each data job require?**  \n",
    "    The goal with this question is to understand which Languages, Databases, Platforms, Web Framework and Dev Environment is used by each data job. The questions on the survey that contains this information are: *['LanguageWorkedWith', 'DatabaseWorkedWith', 'PlatformWorkedWith', 'WebFrameWorkedWith', 'MiscTechWorkedWith', 'DevEnviron', 'OpSys']*\n",
    " \n",
    " \n",
    "- **How is the distribution of salary in the top respondents countries?**  \n",
    "    This question is to understand how the market is paying these jobs, and you understand your position in it. The information is on the foolowing questions: *['ConvertedComp', 'WorkWeekHrs']*. The segment is *['Country']*\n",
    "  \n",
    "  \n",
    "- **How much is worth each skill/technology/education in dollar per hours?**  \n",
    "    The goal is to make a predictor of salary based on your knowledge and skills. The model target will be made on **Dollar per hour**: *['ConvertedComp', 'WorkWeekHrs']*. While the features will be only the subset of skill/technology/education, years of experience and country: *['YearsCodePro', 'Country', 'EdLevel', 'LanguageWorkedWith', 'DatabaseWorkedWith', 'PlatformWorkedWith', 'WebFrameWorkedWith', 'MiscTechWorkedWith', 'DevEnviron', 'OpSys']*\n",
    "\n",
    "#### Segment and Filter  \n",
    "    Our Study will be focused only on data developers: *['Data or business analyst', 'Data scientist or machine learning specialist', 'Database administrator', 'Engineer, data']* and on the employed developers: *['Employed full-time','Employed part-time']*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optionIsInCell(cell, option):\n",
    "    ''' Check if the option is in the cell and return an boolean in the int format.\n",
    "    input:\n",
    "        cell (String)\n",
    "        Option (String)\n",
    "    \n",
    "    output:\n",
    "        1 - The option is in the cell value\n",
    "        0 - The option is not in the cell value\n",
    "    '''\n",
    "    if str(cell).find(option)!=-1:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transformingColumnByOptions(df, column, options, prefix = False, separator='_'):\n",
    "    ''' Create one column for each answer inside an multiple-selection answer\n",
    "    input:\n",
    "        df (dataframe)\n",
    "        column (String)\n",
    "        options (list)\n",
    "        prefix (boolean)\n",
    "        separator (string)\n",
    "    \n",
    "    output:\n",
    "        dataframe - with the aditional columns\n",
    "    '''\n",
    "    df_local = df.copy()\n",
    "    for each in options:\n",
    "        new_column = column + separator + each if prefix else each\n",
    "        df_local[new_column] = df_local[column].apply(optionIsInCell, option = each)\n",
    "    return df_local.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isOneOfTheList(x, list_options):\n",
    "    ''' Check is the argument is one of the list\n",
    "    input:\n",
    "        x (String)\n",
    "        list_options (list)\n",
    "    \n",
    "    output:\n",
    "        boolean - true if x is one of the list_options\n",
    "    '''\n",
    "    for each in list_options:\n",
    "        if each in x:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getOptionOfMultipleSelection(df, column, separator = ';'):\n",
    "    ''' Get a list of the elements inside a string answer\n",
    "    input:\n",
    "        df (dataframe)\n",
    "        column (String)\n",
    "        separator (string)\n",
    "    \n",
    "    output:\n",
    "        list - a list of the elements of the multiple selection\n",
    "    '''\n",
    "    flat_list = []\n",
    "    for sublist in df[column].dropna().str.split(pat=separator, expand=False):\n",
    "        for item in sublist:\n",
    "            if item not in flat_list:\n",
    "                flat_list.append(item)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the data jobs Categories\n",
    "def dataJobsClassificationMicro(DevType):\n",
    "    ''' Transformation to define the subgroups of data jobs\n",
    "    input:\n",
    "        DevType (String)\n",
    "    \n",
    "    output:\n",
    "        string - Data Devtype microgroup\n",
    "    '''\n",
    "    for interest in devtype_interest:\n",
    "        if interest == DevType:\n",
    "            return interest\n",
    "    for interest in devtype_interest:\n",
    "        if interest in DevType:\n",
    "            for not_interest in devtype_not_interest:\n",
    "                if not_interest in DevType:\n",
    "                    return 'Data Partialy'\n",
    "            return 'Data Misture'\n",
    "    return 'Not Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataJobsClassificationMacro(DevType):\n",
    "    ''' Transformation to define the subgroups of data jobs\n",
    "    input:\n",
    "        DevType (String)\n",
    "    \n",
    "    output:\n",
    "        string - Data Devtype majorgroup\n",
    "    '''\n",
    "    for interest in devtype_interest:\n",
    "        if interest == DevType:\n",
    "            return 'Data Job'\n",
    "    for interest in devtype_interest:\n",
    "        if interest in DevType:\n",
    "            for not_interest in devtype_not_interest:\n",
    "                if not_interest in DevType:\n",
    "                    return 'Data Partialy'\n",
    "            return 'Data Job'\n",
    "    return 'Not Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def colourMap(proportion):\n",
    "    ''' Map a proportion to a color\n",
    "    input:\n",
    "        proportion (float [0-1])\n",
    "    \n",
    "    output:\n",
    "        list - RGBT Color \n",
    "    '''\n",
    "    if proportion < 0.05:\n",
    "        return (0.7, 0.0, 0.0, 1)\n",
    "    elif proportion < 0.20:\n",
    "        return (0.5, 0.0, 0.2, 1)\n",
    "    elif proportion < 0.40:\n",
    "        return (0.3, 0.0, 0.4, 1)\n",
    "    elif proportion < 0.60:\n",
    "        return (0.1, 0.0, 0.6, 1)\n",
    "    elif proportion < 0.80:\n",
    "        return (0.0, 0.0, 0.5, 1)\n",
    "    else:\n",
    "        return (0.0, 0.5, 0.0, 1)\n",
    "    return 'error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaningYearsOfCode(text):\n",
    "    ''' Transformation of the strings on the [Year of Code]\n",
    "    input:\n",
    "        text (String)\n",
    "    \n",
    "    output:\n",
    "        float \n",
    "    '''\n",
    "    if text == 'Less than 1 year':\n",
    "        return float(0.5)\n",
    "    elif text == 'More than 50 years':\n",
    "        return float(55)\n",
    "    return float(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('survey_results_public.csv')\n",
    "df_schema = pd.read_csv('survey_results_schema.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Employee  \n",
    "We are only interested on those that are employed. This part will filter then.\n",
    "The columns is **'Employment'**, the question on the survey was *Which of the following best describes your current employment status?* and the answers we are seeking are: *['Employed full-time', 'Employed part-time']*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_raw[ df_raw['Employment'].isin(['Employed full-time','Employed part-time']) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Columns & Decoding  \n",
    "For each column, discover which answers multi-options could be selected. Then decode each column multi-option to a quantity of options columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columnsOptions = {}\n",
    "columnsToGetOptions =[\n",
    "        'DevType'\n",
    "        ,'EdLevel'\n",
    "        ,'LanguageWorkedWith'\n",
    "        ,'DatabaseWorkedWith'\n",
    "        ,'PlatformWorkedWith'\n",
    "        ,'WebFrameWorkedWith'\n",
    "        ,'MiscTechWorkedWith'\n",
    "        ,'DevEnviron'\n",
    "        ,'OpSys'\n",
    "    ]\n",
    "\n",
    "# Creating an dictionary of the columns options\n",
    "for each in columnsToGetOptions:\n",
    "    tempList = getOptionOfMultipleSelection(df,each)\n",
    "    tempList.sort()\n",
    "    columnsOptions[each] = tempList\n",
    "\n",
    "# Creating each skill columns\n",
    "for questionColumn in columnsToGetOptions:\n",
    "    df = transformingColumnByOptions(df, questionColumn, columnsOptions[questionColumn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmenting Data Jobs  \n",
    "We are interested on data Jobs. So Lets create those categories. The columns is **'DevType'**, the question on the survey was *Which of the following describe you? Please select all that apply.* and the answers we are seeking are: *['Data or business analyst', 'Data scientist or machine learning specialist', 'Database administrator', 'Engineer, data']*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A list of each data we are interested in\n",
    "devtype_interest = [\n",
    "    'Data or business analyst'\n",
    "    ,'Data scientist or machine learning specialist'\n",
    "    ,'Database administrator'\n",
    "    ,'Engineer, data'\n",
    "]\n",
    "\n",
    "# Getting a list of the other jobs\n",
    "devtype_not_interest = []\n",
    "for each in columnsOptions['DevType']:\n",
    "    if not each in devtype_interest:\n",
    "        devtype_not_interest.append(each)\n",
    "\n",
    "# A list of the classification of a DevType\n",
    "dataJobsOutputs = [\n",
    "    'Data or business analyst'\n",
    "    ,'Data scientist or machine learning specialist'\n",
    "    ,'Database administrator'\n",
    "    ,'Engineer, data'\n",
    "    ,'Data Misture'\n",
    "    ,'Data Partially'\n",
    "    ,'Not Data'\n",
    "]\n",
    "\n",
    "# Cleaning dataframe from no answer of devtype\n",
    "df = df.dropna(subset = ['DevType']).copy()\n",
    "\n",
    "# Defining devtype on the dataJobsOutputs classification\n",
    "df['datajobsCategoryMicro'] = df['DevType'].apply( dataJobsClassificationMicro )\n",
    "df['datajobsCategoryMacro'] = df['DevType'].apply( dataJobsClassificationMacro )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the dataset volume of answer by job\n",
    "Below we can see that we only a few hundreds of each data job type. While there some thousands that are partially on this classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datajobsCategoryMicro'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Which skills and technologies each data job require?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting every skill category by job segment (Micro and Macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Micro Segment Plot\n",
    "for eachOutput in devtype_interest:\n",
    "    groupedResults = df[df['datajobsCategoryMicro']==eachOutput].groupby(['datajobsCategoryMicro']).mean()\n",
    "    for skill in columnsOptions:\n",
    "            groupedSkill = groupedResults.reset_index()[columnsOptions[skill]].transpose().sort_values(0,ascending=True)\n",
    "            colour = groupedSkill[0].apply(colourMap)\n",
    "            ysize = groupedSkill.shape[0]/3.5\n",
    "            groupedSkill.plot.barh(figsize=(10,max(ysize,3)), color=colour)\n",
    "            plt.title(eachOutput + ' - ' + skill)\n",
    "            plt.xlim((0,1))\n",
    "            \n",
    "            legendPlot_100 = plt.scatter([-1], [-1], color=colourMap(0.90))\n",
    "            legendPlot_80l = plt.scatter([-1], [-1], color=colourMap(0.70))\n",
    "            legendPlot_60l = plt.scatter([-1], [-1], color=colourMap(0.50))\n",
    "            legendPlot_40l = plt.scatter([-1], [-1], color=colourMap(0.30))\n",
    "            legendPlot_20l = plt.scatter([-1], [-1], color=colourMap(0.10))\n",
    "            legendPlot_05l = plt.scatter([-1], [-1], color=colourMap(0.04))\n",
    "            plt.legend((legendPlot_100,legendPlot_80l,legendPlot_60l,legendPlot_40l,legendPlot_20l,legendPlot_05l),\n",
    "                       ('Not an Option','Must know','Should know','Good to know','Specifics uses','Extremely specific'))\n",
    "            \n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACRO SEGMENT PLOT\n",
    "groupedResults = df.groupby(['datajobsCategoryMacro']).mean()\n",
    "for skill in columnsOptions:\n",
    "        groupedResults.reset_index()[columnsOptions[skill]].transpose().plot.barh(figsize=(8,8))\n",
    "        plt.legend(groupedResults.index)\n",
    "        plt.title(skill)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: How is the distribution of Salary, for each type of data job in the top 10 countries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Salary\n",
    "    The salary varies by country, currency, frequency of payment and hours worked. To make an fair metric, we will create the DollarPerHour variable and segment our analysis by country. This way our measurement will be fair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating feature of dollar paid per Hour\n",
    "weeksInYear = 52\n",
    "df['DollarPerHour'] = df['ConvertedComp']/df['WorkWeekHrs']/weeksInYear\n",
    "\n",
    "# Filtering data Jobs\n",
    "dfSalary = df[df['datajobsCategoryMacro']=='Data Job']\n",
    "\n",
    "# Clearing null data\n",
    "dfSalary = dfSalary.dropna( subset = ['Country','DollarPerHour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selecting top 5 and Brasil\n",
    "topCountry = dfSalary['Country'].value_counts().head(5)\n",
    "countries_list = list(topCountry.index)\n",
    "countries_list.append('Brazil')\n",
    "\n",
    "countries_df = dfSalary[dfSalary['Country'].isin(countries_list)]['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints data jobs income per hour by country\n",
    "for country in countries_df.index:\n",
    "    tempdfSalary = dfSalary[dfSalary['Country']==country]['DollarPerHour']\n",
    "    nbins = 5*tempdfSalary.max()/tempdfSalary.median()\n",
    "    tempdfSalary.hist(bins=int(nbins), ec='black')\n",
    "    plt.title(country)\n",
    "    plt.xlim(0,100)\n",
    "    plt.xlabel('Dollars Per Hour')\n",
    "    plt.ylabel('Qtd of respondents')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: **How much is worth each skill/technology/education in dollar per hours?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Using all the dataset, let understand which skills are more valued."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting a clean Dataframe and filtering employed\n",
    "df_model = df_raw[ df_raw['Employment'].isin(['Employed full-time','Employed part-time']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filtering for a country, because of cost of living.\n",
    "\n",
    "# United States, India, Germany, United Kingdom, Canada, France, Brazil,\n",
    "# Australia, Netherlands, Poland, Spain, Russian Federation, Italy,\n",
    "# Sweden, Switzerland, Israel, Turkey, Austria, Ukraine\n",
    "\n",
    "# filterCountry = 'Brazil'\n",
    "filterCountry = 'United States'\n",
    "\n",
    "df_model = df_model[df_model['Country']==filterCountry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature eng.\n",
    "\n",
    "# Creating feature of dollar paid per Hour\n",
    "weeksInYear = 52\n",
    "df_model['DollarPerHour'] = df_model['ConvertedComp']/df_model['WorkWeekHrs']/weeksInYear\n",
    "\n",
    "#Cleaning null and zeros\n",
    "df_model = df_model.dropna( subset = ['DollarPerHour'] )\n",
    "df_model = df_model[df_model['DollarPerHour']!=0]\n",
    "\n",
    "# Scaling\n",
    "df_model['DollarPerHourLog'] = np.log10(df_model['DollarPerHour'])\n",
    "\n",
    "# Transforming The years of code in a numeric variable\n",
    "df_model['YearsCodeProFix'] = df_model['YearsCodePro'].apply(cleaningYearsOfCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelcolumnsOptions = {}\n",
    "modelColumnsCategorical =[\n",
    "    'DevType'\n",
    "    ,'EdLevel'\n",
    "    ,'LanguageWorkedWith'\n",
    "    ,'DatabaseWorkedWith'\n",
    "    ,'PlatformWorkedWith'\n",
    "    ,'WebFrameWorkedWith'\n",
    "    ,'MiscTechWorkedWith'\n",
    "    ,'DevEnviron'\n",
    "    ,'OpSys'\n",
    "]\n",
    "\n",
    "modelColumns = [\n",
    "    'YearsCodeProFix' \n",
    "]\n",
    "    \n",
    "targetColumns = ['DollarPerHour'] # DollarPerHour, DollarPerHourLog\n",
    "\n",
    "# Creating an dictionary of the columns options\n",
    "for each in modelColumnsCategorical:\n",
    "    tempList = getOptionOfMultipleSelection(df_model,each)\n",
    "    tempList.sort()\n",
    "    modelcolumnsOptions[each] = tempList\n",
    "\n",
    "# Creating each skill columns\n",
    "for each in modelColumnsCategorical:\n",
    "    df_model = transformingColumnByOptions(df_model, each, columnsOptions[each])\n",
    "    \n",
    "# Defining a list of the model feature columns\n",
    "for eachColumn in modelcolumnsOptions:\n",
    "    for eachOption in modelcolumnsOptions[eachColumn]:\n",
    "        modelColumns.append(eachOption)\n",
    "        \n",
    "# Filling NA by Medium\n",
    "df_model = df_model.fillna(df_model.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_model[modelColumns], \n",
    "                                                    df_model[targetColumns], \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = {}\n",
    "model['LinearRegression'] = {'model':LinearRegression()}\n",
    "model['Lasso'] = {'model':Lasso()}\n",
    "model['DecisionTreeRegressor'] = {'model':DecisionTreeRegressor(min_samples_split=20,max_depth=5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for eachModel in model:\n",
    "    model[eachModel]['model'].fit(X_train, y_train)\n",
    "    model[eachModel]['predTrain'] = model[eachModel]['model'].predict(X_train)\n",
    "    model[eachModel]['predTest'] = model[eachModel]['model'].predict(X_test)\n",
    "    model[eachModel]['trainR2'] = r2_score( y_train, model[eachModel]['predTrain'] )\n",
    "    model[eachModel]['testR2'] = r2_score( y_test, model[eachModel]['predTest'] )\n",
    "    model[eachModel]['trainMSE'] = mean_squared_error( y_train, model[eachModel]['predTrain'] )\n",
    "    model[eachModel]['testMSE'] = mean_squared_error( y_test, model[eachModel]['predTest'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating benchmark model\n",
    "model['Median Model'] = {'model':y_train.median()[0]}\n",
    "model['Median Model']['predTrain'] = [y_train.median()[0]] * X_train.shape[0]\n",
    "model['Median Model']['predTest']  = [y_train.median()[0]] * X_test.shape[0]\n",
    "model['Median Model']['trainR2']   = r2_score( y_train, model['Median Model']['predTrain'] )\n",
    "model['Median Model']['testR2']    = r2_score( y_test, model['Median Model']['predTest'] )\n",
    "model['Median Model']['trainMSE']  = mean_squared_error( y_train, model['Median Model']['predTrain'] )\n",
    "model['Median Model']['testMSE']   = mean_squared_error( y_test, model['Median Model']['predTest'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing Results\n",
    "for eachModel in model:\n",
    "    print('-------')\n",
    "    print('Model: %s' % (eachModel) )\n",
    "    print('R2  train: %.2f  R2  test: %.2f' % (model[eachModel]['trainR2'],model[eachModel]['testR2']))\n",
    "    print('MSE train: %.2f  MSE test: %.2f' % (model[eachModel]['trainMSE'],model[eachModel]['testMSE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Checking for correlation on the knowledge variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_target_corr = df_model[targetColumns + modelColumns].corr()[targetColumns]\n",
    "df_target_corr['absolute_corr'] = df_target_corr['DollarPerHour'].apply(abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_corr.sort_values(by=['absolute_corr'],ascending=True)[['absolute_corr']].plot.barh(figsize=(5,30))\n",
    "plt.xlabel('Pearson Correlation')\n",
    "plt.title('Pearson Correlation to DollarPerHour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Article main Image\n",
    "\n",
    "This part of the code was used to create the article main image. Just ignore this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read this post!\n"
     ]
    }
   ],
   "source": [
    "# import Datajobs\n",
    "\n",
    "# analyst = Datajobs(devtype = 'Data Analyst')\n",
    "\n",
    "# analyst.learn('python')\n",
    "# analyst.learn('sql')\n",
    "# analyst.learn('R')\n",
    "\n",
    "# analyst.nextsteps('?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Read this post!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
